{"id": "c61cbd659b1d_meta", "paper_id": "c61cbd659b1d", "section": "meta", "text": "논문: MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo\n저자: Byeonggwon Lee, Junkyu Park, Khang Truong Giang\n발표:  (2025)\n인용: 3회\n키워드: 온라인 멀티뷰 스테레오, 3D Gaussian Splatting, 신경 렌더링, 밀집 SLAM, 3D 모델링, 깊이 추정\n문제: 네트워크 렌더링을 위한 정확한 온라인 3D 모델 생성 도전 해결\n방법: 온라인 MVS 접근 방식을 사용한 고품질 3DGS 모델링 프레임워크\n결과: 실내 PSNR 2 dB 개선, 실외 및 대규모 공중 장면 PSNR 10.28 dB 향상", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.359, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo", "year": 2025, "venue": "", "citations": 3}}
{"id": "c61cbd659b1d_abstract", "paper_id": "c61cbd659b1d", "section": "abstract", "text": "이 연구는 RGB 이미지 스트림을 사용하여 온라인 3D 모델 생성을 위한 문제를 해결합니다. 기존 연구는 Neural Radiance Fields (NeRF) 또는 3D Gaussian Splatting (3DGS)을 사용한 장면 표현을 통합했지만, 대체로 세밀한 재구성을 달성하기보다는 대략적인 3D 장면 추정에 주로 초점을 맞추었습니다. 이러한 제약을 극복하기 위해 온라인 멀티뷰 스테레오(MVS) 접근방식을 활용하여 고품질 3DGS 모델링을 위한 새로운 프레임워크를 제안합니다. 제안된 방법은 시퀀스 프레임에서 MVS 깊이를 추정하고 포괄적인 깊이 세분화 기술을 적용하여 이상값을 제거합니다.", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.2872, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_method", "paper_id": "c61cbd659b1d", "section": "method", "text": "온라인 MVS를 사용하여 3DGS 모델을 고품질로 생성하는 새로운 프레임워크 제안. 깊이 필터링 프로세스를 포함하여 시퀀스 프레임에서 깊이를 추정하고 강력한 지오메트릭 프라이어를 통합함.", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.2872, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_results", "paper_id": "c61cbd659b1d", "section": "results", "text": "제안된 방법은 첨단 밀집 SLAM 방법들보다 실내 장면에서 평균 PSNR 2 dB 개선을 달성했으며, 복잡한 실외 장면이나 대규모 공중 장면에서도 견고한 모델을 생성하며, 기존 방법 대비 PSNR 10.28 dB 향상을 기록하였습니다.", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.2872, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_contributions", "paper_id": "c61cbd659b1d", "section": "contributions", "text": "논문 \"MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo\"의 핵심 기여:\n- 고품질 3DGS 매핑 프레임워크 제안\n- 온라인 MVS 기법에 의한 포괄적인 깊이 필터링 통합\n\n제안 방법: 온라인 MVS 접근 방식을 사용한 고품질 3DGS 모델링 프레임워크", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.359, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "9eac4875c0cd_meta", "paper_id": "9eac4875c0cd", "section": "meta", "text": "논문: Online 3D Gaussian Splatting Modeling with Novel View Selection\n저자: Byeonggwon Lee, Junkyu Park, Khang Truong Giang\n발표:  (2025)\n인용: 1회\n키워드: 3D Gaussian Splatting, 뷰 선택, 모델 완전성, 온라인 3D 모델링, 복셀 기반 렌더링\n문제: 키프레임에만 의존하여 3D 모델의 불완전한 재구성과 범용성 부족\n방법: 비키프레임을 효과적으로 활용하여 3DGS 모델의 완전성을 개선하는 적응적 뷰 선택 방법 제안\n결과: 제안된 방법은 두 개의 벤치마크를 활용한 실험에서 기존 방법을 능가하는 성능을 보이며, 특히 복잡한 야외 장면에서도 탁월한 성능을 입증했습니다.", "keywords": ["3D Gaussian Splatting", "뷰 선택", "모델 완전성", "온라인 3D 모델링", "복셀 기반 렌더링"], "importance": 0.253, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection", "year": 2025, "venue": "", "citations": 1}}
{"id": "9eac4875c0cd_abstract", "paper_id": "9eac4875c0cd", "section": "abstract", "text": "이 연구에서는 RGB 프레임만을 이용해 온라인 3D Gaussian Splatting(3DGS) 모델을 생성하는 문제를 다룹니다. 기존 기술들은 키프레임만을 사용하여 제한된 장면 정보를 기반으로 3DGS 모델을 구축했으나, 이는 장면의 불완전한 재구성을 초래했습니다. 이러한 한계를 극복하기 위해 우리는 재구성 품질을 온라인으로 분석하여 최적의 비키프레임을 선택하고, 이를 추가 학습에 활용하여 모델의 완전성을 개선하는 방법을 제안합니다.", "keywords": ["3D Gaussian Splatting", "뷰 선택", "모델 완전성", "온라인 3D 모델링", "복셀 기반 렌더링"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_problem", "paper_id": "9eac4875c0cd", "section": "problem", "text": "이전 연구에서는 키프레임만을 사용하여 3D 장면을 추정함으로써 전체 장면을 포착할 수 없고 재구성의 완전성을 제약받았습니다.", "keywords": ["3D Gaussian Splatting", "뷰 선택", "모델 완전성", "온라인 3D 모델링", "복셀 기반 렌더링"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_method", "paper_id": "9eac4875c0cd", "section": "method", "text": "본 논문에서는 새로운 뷰 선택 방법을 통해 비키프레임을 적절히 선택하여 3DGS 모델의 완전성을 향상시키는 방법을 제안합니다. 이 방법은 Gaussian primitive의 불확실성을 분석하여 최적의 뷰를 선택하고, 키프레임 및 비키프레임을 결합하여 다양한 시점에서 모델을 최적화합니다.", "keywords": ["3D Gaussian Splatting", "뷰 선택", "모델 완전성", "온라인 3D 모델링", "복셀 기반 렌더링"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_results", "paper_id": "9eac4875c0cd", "section": "results", "text": "실험 결과 제안된 방법이 특히 복잡한 야외 장면에서 최첨단 방법들보다 뛰어난 성능을 보여줍니다.", "keywords": ["3D Gaussian Splatting", "뷰 선택", "모델 완전성", "온라인 3D 모델링", "복셀 기반 렌더링"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_contributions", "paper_id": "9eac4875c0cd", "section": "contributions", "text": "논문 \"Online 3D Gaussian Splatting Modeling with Novel View Selection\"의 핵심 기여:\n- 적응적 뷰 선택을 통한 모델의 완전성 향상\n- 상태 최적의 MVS 네트워크 통합 및 온라인 3DGS 프레임워크 제안\n\n제안 방법: 비키프레임을 효과적으로 활용하여 3DGS 모델의 완전성을 개선하는 적응적 뷰 선택 방법 제안", "keywords": ["3D Gaussian Splatting", "뷰 선택", "모델 완전성", "온라인 3D 모델링", "복셀 기반 렌더링"], "importance": 0.253, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "ebd43503423c_meta", "paper_id": "ebd43503423c", "section": "meta", "text": "논문: Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation\n저자: Junkyu Park, Byeonggwon Lee, Sanggi Lee\n발표:  (2025)\n인용: 0회\n키워드: 3D Gaussian Splatting, SLAM, stereo depth estimation, online mapping, neural rendering\n문제: 기존 3DGS 방법의 온라인 SLAM 시나리오에서의 제약\n방법: 스테레오 깊이 추정을 기반으로 한 3DGS 재구성 프레임워크\n결과: Stereo-GS는 EuRoC에서 평균 PSNR 23.70, TartanAir에서 22.47을 기록하며 기존 방법보다 뛰어난 성능을 입증했습니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.35, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation", "year": 2025, "venue": "", "citations": 0}}
{"id": "ebd43503423c_abstract", "paper_id": "ebd43503423c", "section": "abstract", "text": "Stereo-GS는 스트리밍 스테레오 이미지 쌍으로부터 포토리얼리스틱한 3D 장면을 실시간으로 재구성하는 온라인 3D Gaussian Splatting(3DGS) 시스템을 소개합니다. 본 시스템은 사전 계산된 깊이나 밀집 멀티뷰 입력 없이 직렬화된 스테레오 기하학으로부터 메트릭이 정확한 깊이 맵을 추정하여 점진적이고 전역적으로 일관된 재구성을 가능하게 합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_problem", "paper_id": "ebd43503423c", "section": "problem", "text": "기존의 3DGS 방법은 오프라인 작동을 위해 설계되어 있으며, 사전 계산된 깊이 맵이나 밀집 멀티뷰 관찰에 의존합니다. 이는 온라인 SLAM 시나리오에서의 적용성을 제한합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_method", "paper_id": "ebd43503423c", "section": "method", "text": "본 연구에서는 실시간 스테레오 이미지 스트림으로부터 온라인 3DGS 모델링을 위한 Stereo-GS 프레임워크를 제안합니다. 스테레오 구현된 DROID-SLAM과 FoundationStereo를 사용하여 정확한 깊이 맵을 생성하고, 이를 기반으로 3DGS 모델을 구축하고 최적화합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_results", "paper_id": "ebd43503423c", "section": "results", "text": "Stereo-GS는 EuRoC와 TartanAir에서 각각 0.22 dB 및 2.45 dB의 PSNR 향상을 이루며, 온라인 3DGS-SLAM 방법을 초과하는 성능을 보였습니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_contributions", "paper_id": "ebd43503423c", "section": "contributions", "text": "논문 \"Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation\"의 핵심 기여:\n- 스테레오 깊이 추정을 기반으로 한 3DGS 재구성 프레임워크 제안\n- 견고한 스테레오 기반 깊이 추정 파이프라인 도입\n\n제안 방법: 스테레오 깊이 추정을 기반으로 한 3DGS 재구성 프레임워크", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.35, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "07af93b9bae7_meta", "paper_id": "07af93b9bae7", "section": "meta", "text": "논문: M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo\n저자: Anonymous\n발표: CVPR (2026)\n인용: 0회\n키워드: Multi-View Stereo, Depth Foundation Models, 3D Reconstruction, Bidirectional Refinement, Cost Volume Refinement\n문제: 기존 MVS과 단일 사진 기반 방법론의 한계 극복\n방법: 깊이 기초 모델과 MVS를 양방향으로 통합\n결과: 다양한 벤치마크에서 기존 MVS 방법을 능가하며 고도의 정확성과 일반화를 달성.", "keywords": ["Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement", "Cost Volume Refinement"], "importance": 0.6, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo", "year": 2026, "venue": "CVPR", "citations": 0}}
{"id": "07af93b9bae7_abstract", "paper_id": "07af93b9bae7", "section": "abstract", "text": "이 논문은 깊이 기반 단일 사진 및 다중 뷰 스테레오(MVS) 기법을 통합한 혁신적인 프레임워크를 제안하고 있으며, MVS 중심의 기존 방법론과 비교하여 정확한 깊이 맵과 정밀한 3D 구조를 달성한다.", "keywords": ["Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement", "Cost Volume Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_problem", "paper_id": "07af93b9bae7", "section": "problem", "text": "기존의 MVS 및 단일 사진 중심의 방법론들은 규모 모호성 및 기하학적 일관성의 측면에서 제한적이며, 서로의 강점을 완전히 활용하지 못한다.", "keywords": ["Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement", "Cost Volume Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_method", "paper_id": "07af93b9bae7", "section": "method", "text": "본 연구에서는 깊이 기초 모델(DFM)과 MVS 파이프라인을 긴밀히 연결하는 양방향 상호 정제 전략을 도입하고, 주의 메커니즘에 기반한 비용 볼륨 정제 메커니즘을 제안한다.", "keywords": ["Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement", "Cost Volume Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_results", "paper_id": "07af93b9bae7", "section": "results", "text": "제안된 방법론은 기존의 최첨단 MVS 방법론을 능가하며, 스파스 뷰 환경에서도 완전하고 일반화된 깊이 맵을 생성한다.", "keywords": ["Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement", "Cost Volume Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_contributions", "paper_id": "07af93b9bae7", "section": "contributions", "text": "논문 \"M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo\"의 핵심 기여:\n- 새로운 MVS 프레임워크를 도입하여 복잡한 상황에서도 깨끗하고 완전한 깊이 맵을 생성.\n- 양방향의 상호 정제 메커니즘을 제안하여 MVS와 단일 사진의 강점을 동시에 활용.\n- 단일 사진과 MVS 정보를 융합하여 지역적인 기하학적 일관성을 강화하는 비용 볼륨 정제 전략을 제안.\n\n제안 방법: 깊이 기초 모델과 MVS를 양방향으로 통합", "keywords": ["Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement", "Cost Volume Refinement"], "importance": 0.6, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
