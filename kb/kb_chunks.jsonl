{"id": "c61cbd659b1d_meta", "paper_id": "c61cbd659b1d", "section": "meta", "text": "논문: MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo\n저자: Byeonggwon Lee, Junkyu Park, Khang Truong Giang\n발표:  (2025)\n인용: 3회\n키워드: 온라인 멀티뷰 스테레오, 3D Gaussian Splatting, 신경 렌더링, 밀집 SLAM, 3D 모델링, 깊이 추정\n문제: RGB 이미지에서 실시간으로 3D 모델을 생성하는 어려움\n방법: 온라인 MVS를 사용하여 고품질의 3DGS 모델을 생성\n결과: 실내 장면에서 PSNR 평균 약 2 dB 개선, 대규모 항공 장면에서 10.28 dB 개선", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.359, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo", "year": 2025, "venue": "", "citations": 3}}
{"id": "c61cbd659b1d_abstract", "paper_id": "c61cbd659b1d", "section": "abstract", "text": "이 연구는 RGB 이미지 스트림을 사용한 신경 렌더링을 위한 온라인 3D 모델 생성의 도전에 대해 다룹니다. 기존 연구는 Neural Radiance Fields (NeRF) 또는 3D Gaussian Splatting (3DGS)를 사용하는 장면 표현을 밀집 SLAM 방법과 통합하였지만, 대부분은 상세한 복원보다는 거친 3D 장면 추정에 중점을 둡니다. 이 연구는 온라인 멀티뷰 스테레오 (MVS) 접근 방식을 활용하여 고품질 3DGS 모델링을 위한 새로운 프레임워크를 제안합니다.", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.2872, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_problem", "paper_id": "c61cbd659b1d", "section": "problem", "text": "기존의 3D 모델 생성 방법은 대개 거친 3D 장면을 추정하는 데 중점을 두며, 이미지 기반의 깊이 추정은 모호하여 낮은 품질의 3D 모델을 초래합니다.", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.2872, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_method", "paper_id": "c61cbd659b1d", "section": "method", "text": "온라인 MVS 접근 방식을 사용하여 MVS 깊이를 추정하고 깊이 정제 기술을 적용하여 고품질의 3DGS 모델을 생성합니다. 이 프레임워크는 병렬화된 백엔드 모듈을 도입하여 매 새로운 키 프레임마다 효율적으로 3DGS 모델을 최적화합니다.", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.2872, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_results", "paper_id": "c61cbd659b1d", "section": "results", "text": "실험 결과, 실내 장면에서 PSNR 평균 약 2 dB 개선 및 복잡한 실외 장면에서 안정적인 3D 모델 생산을 포함하여 최신 밀집 SLAM 방법들을 능가하는 성능을 보였습니다.", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.2872, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_contributions", "paper_id": "c61cbd659b1d", "section": "contributions", "text": "논문 \"MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo\"의 핵심 기여:\n- 고품질 3DGS 매핑을 위한 새로운 프레임워크 제안\n- 온라인 MVS를 통한 정밀한 깊이 필터링 과정 도입\n\n제안 방법: 온라인 MVS를 사용하여 고품질의 3DGS 모델을 생성", "keywords": ["온라인 멀티뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "밀집 SLAM", "3D 모델링", "깊이 추정"], "importance": 0.359, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "9eac4875c0cd_meta", "paper_id": "9eac4875c0cd", "section": "meta", "text": "논문: Online 3D Gaussian Splatting Modeling with Novel View Selection\n저자: Byeonggwon Lee, Junkyu Park, Khang Truong Giang\n발표:  (2025)\n인용: 1회\n키워드: 3DGS, SLAM, Gaussian Splatting, MVS, Depth Estimation\n문제: 기존 3DGS 모델링의 불완전함을 극복\n방법: 적응형 뷰 선택과 비키프레임 활용을 통한 3DGS 모델링 개선\n결과: 제안된 방법론이 기존 최신 방법들보다 높은 성능을 보여줌", "keywords": ["3DGS", "SLAM", "Gaussian Splatting", "MVS", "Depth Estimation"], "importance": 0.253, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection", "year": 2025, "venue": "", "citations": 1}}
{"id": "9eac4875c0cd_abstract", "paper_id": "9eac4875c0cd", "section": "abstract", "text": "이 연구에서는 RGB 프레임만을 사용하여 온라인 3D Gaussian Splatting (3DGS) 모델을 생성하는 문제를 다루고 있습니다. 기존의 연구들은 키프레임에만 의존하여 전체 장면을 캡처하지 못해 불완전한 재구성이 발생하는 문제를 가지고 있었습니다. 이 연구는 적응형 뷰 선택을 통해 모델의 완성도를 향상시키는 새로운 방법을 제안합니다. 온라인으로 재구성 품질을 분석하여 추가 훈련을 위한 최적의 비키프레임을 선택함으로써 모델 완성도를 높이는 방법론을 제시합니다.", "keywords": ["3DGS", "SLAM", "Gaussian Splatting", "MVS", "Depth Estimation"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_problem", "paper_id": "9eac4875c0cd", "section": "problem", "text": "기존 방법들이 키프레임만으로는 장면 전체를 캡처하기 어렵다는 문제와 온라인 처리의 제약으로 인한 프레임 수와 훈련 반복의 한계점을 극복하는 것이 주요 문제입니다.", "keywords": ["3DGS", "SLAM", "Gaussian Splatting", "MVS", "Depth Estimation"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_method", "paper_id": "9eac4875c0cd", "section": "method", "text": "이 논문에서는 Gaussian 원시 형태와 위치의 기울기를 바탕으로 불확실성을 정의하고 이를 통해 정보 획득을 계산하는 새로운 방법을 제안합니다. 이는 비키프레임의 최적 뷰를 선택하게 해주며, 모든 프레임을 효율적으로 사용하는 3DGS 매핑 프레임워크를 소개합니다.", "keywords": ["3DGS", "SLAM", "Gaussian Splatting", "MVS", "Depth Estimation"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_results", "paper_id": "9eac4875c0cd", "section": "results", "text": "제안된 방법론이 기존 최신 기법들보다 복잡한 야외 환경에서 높은 성능을 보여주며, 두 가지 벤치마크 테스트에서 그 일반화 가능성을 입증했습니다.", "keywords": ["3DGS", "SLAM", "Gaussian Splatting", "MVS", "Depth Estimation"], "importance": 0.20240000000000002, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_contributions", "paper_id": "9eac4875c0cd", "section": "contributions", "text": "논문 \"Online 3D Gaussian Splatting Modeling with Novel View Selection\"의 핵심 기여:\n- 대학교 3DGS 모델링을 위한 새로운 뷰 선택 접근법 제안\n- 불확실성 정의를 통한 효과적인 비키프레임 선택\n\n제안 방법: 적응형 뷰 선택과 비키프레임 활용을 통한 3DGS 모델링 개선", "keywords": ["3DGS", "SLAM", "Gaussian Splatting", "MVS", "Depth Estimation"], "importance": 0.253, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "ebd43503423c_meta", "paper_id": "ebd43503423c", "section": "meta", "text": "논문: Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation\n저자: Junkyu Park, Byeonggwon Lee, Sanggi Lee\n발표:  (2025)\n인용: 0회\n키워드: 3D Gaussian Splatting, SLAM, stereo depth estimation, online mapping, neural rendering\n문제: 기존 3DGS 방법의 온라인 SLAM에의 부적합성 해결\n방법: 실시간 스테레오 이미지 스트림을 사용하는 3D Gaussian Splatting 프레임워크 개발\n결과: EuRoC에서 평균 PSNR 23.70, TartanAir에서 22.47을 기록하며 뛰어난 성능을 입증", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.35, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation", "year": 2025, "venue": "", "citations": 0}}
{"id": "ebd43503423c_abstract", "paper_id": "ebd43503423c", "section": "abstract", "text": "이 논문은 실시간 입체 이미지 스트림을 사용하여 온라인 3D 가우시안 스플래팅(3DGS)을 실현하는 실시간 시스템, Stereo-GS를 소개합니다. Stereo-GS는 사전 계산된 깊이 또는 조밀한 다중 뷰 입력을 필요로 하지 않으며, 정류된 스테레오 기하에서 직접 깊이 지도를 추정하여 점진적이고 전역적으로 일관된 3D 재구성을 가능하게 합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_problem", "paper_id": "ebd43503423c", "section": "problem", "text": "기존의 3D Gaussian Splatting 방법들이 오프라인에서만 작동하며, 사전 계산된 깊이 지도에 의존한다는 점에서 제한적이었습니다. 이러한 방법들은 온라인 SLAM 시나리오에 적합하지 않습니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_method", "paper_id": "ebd43503423c", "section": "method", "text": "Stereo-GS는 실시간 스테레오 이미지 스트림에서 3DGS 모델을 온라인으로 생성하는 프레임워크를 제안합니다. 전면에는 DROID-SLAM의 스테레오 구현을 사용하여 카메라 포즈와 깊이를 추정하고, FoundationStereo 네트워크를 통해 정확한 깊이 추정을 제공합니다. 후면에서는 선택적으로 새로운 가우시안 프리미티브를 초기화하고, 주기적으로 글로벌 번들 조정을 수행하며, 차별 가능한 렌더링을 통해 가우시안 매개 변수를 지속적으로 최적화합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_results", "paper_id": "ebd43503423c", "section": "results", "text": "Stereo-GS는 EuRoC 및 TartanAir 데이터셋에서 최신 성능을 자랑하며, 각각 0.22dB 및 2.45dB의 PSNR 개선을 이뤘습니다. 고품질의 시각적 결과를 제공하며, 고충실도의 기하학적으로 정확한 3D 재구성을 제공합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.27999999999999997, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_contributions", "paper_id": "ebd43503423c", "section": "contributions", "text": "논문 \"Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation\"의 핵심 기여:\n- 스테레오 깊이 추정을 통한 온라인 3DGS 재구성 프레임워크 제안\n- 튼튼한 스테레오 기반 깊이 추정 파이프라인 도입\n\n제안 방법: 실시간 스테레오 이미지 스트림을 사용하는 3D Gaussian Splatting 프레임워크 개발", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.35, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "07af93b9bae7_meta", "paper_id": "07af93b9bae7", "section": "meta", "text": "논문: M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo\n저자: Anonymous\n발표: CVPR (2026)\n인용: 0회\n키워드: MVS, DFM, 양방향 융합, 3D 재구성\n문제: 시야 겹침이 적거나 복잡한 기하학적 구조에서 MVS의 일반화 어려움\n방법: DFM과 MVS 깊이를 양방향으로 통합하여 깊이 추정 정확도 향상\n결과: 다양한 벤치마크에서 최첨단 MVS 방법을 능가하며, 코드가 공개됨", "keywords": ["MVS", "DFM", "양방향 융합", "3D 재구성"], "importance": 0.6, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo", "year": 2026, "venue": "CVPR", "citations": 0}}
{"id": "07af93b9bae7_abstract", "paper_id": "07af93b9bae7", "section": "abstract", "text": "이 논문에서는 최근 몇 년간 Multi-View Stereo (MVS)를 기반으로 한 심층 학습이 크게 발전했지만, 특히 가려진 영역이나 시야 겹침이 적은 지역에서는 새로운 장면에 대한 일반화가 잘 안 되는 문제를 해결하고자 합니다. 이를 위해, Depth Foundation Models (DFMs)를 MVS 파이프라인에 통합하여 단안 깊이 우선 순위를 제공하는 방식이 제안되었습니다. 하지만 기존 방식은 정적이고 단방향의 융합을 사용하여 두 모달리티의 상호 보완적 강점을 충분히 활용하지 못합니다. 본 연구에서는 DFM을 계단식 MVS 파이프라인과 강하게 결합한 새로운 프레임워크를 제안합니다. 양방향 상호 개선 전략을 통해 단안과 MVS 깊이 표현이 단계적으로 개선되며, 주목 기반 융합과 이산 깊이 bin을 사용하여 지역 기하학적 일관성을 촉진합니다. 종합적인 실험에서 우리의 접근법이 벤치마크 데이터셋에서 최신 MVS 방법을 능가한다는 것이 입증됐습니다.", "keywords": ["MVS", "DFM", "양방향 융합", "3D 재구성"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_problem", "paper_id": "07af93b9bae7", "section": "problem", "text": "MVS는 복잡한 기하학적 구조, 시점 변화, 까다로운 조명 조건에서 새로운 장면 구조에 잘 적응하지 못하며, 가려진 영역이나 시야 겹침이 적은 지역에서 정확도가 크게 떨어집니다.", "keywords": ["MVS", "DFM", "양방향 융합", "3D 재구성"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_method", "paper_id": "07af93b9bae7", "section": "method", "text": "우리는 DFM과 계단식 MVS 파이프라인을 강하게 결합하여 양방향 상호 개선 전략을 도입했습니다. 이 방법은 반복적이고 양방향적으로 작동하여 단안과 MVS 깊이가 상호 참조하며 상호 보완합니다. 또한, 비용 볼륨 정제 메커니즘을 제안하여 다중 시야와 단안 정보를 효과적으로 융합합니다.", "keywords": ["MVS", "DFM", "양방향 융합", "3D 재구성"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_results", "paper_id": "07af93b9bae7", "section": "results", "text": "우리의 접근법은 다양한 벤치마크에서 최첨단 MVS 방법을 능가하며, 특히 어려운 영역에서 높은 완벽성과 일반화 성능을 보여주었습니다.", "keywords": ["MVS", "DFM", "양방향 융합", "3D 재구성"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_contributions", "paper_id": "07af93b9bae7", "section": "contributions", "text": "논문 \"M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo\"의 핵심 기여:\n- DFM과 MVS를 통합하여 3D 재구성을 보장하는 새로운 MVS 프레임워크 제안\n- MVS 깊이를 사용하여 단안의 규모 일관성을 맞추는 양방향 상호 개선 메커니즘 제안\n\n제안 방법: DFM과 MVS 깊이를 양방향으로 통합하여 깊이 추정 정확도 향상", "keywords": ["MVS", "DFM", "양방향 융합", "3D 재구성"], "importance": 0.6, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "4df008a0b04d_meta", "paper_id": "4df008a0b04d", "section": "meta", "text": "논문: Online 3D Gaussian Splatting Mapping via Online Multi-View Stereo\n저자: 이병권\n발표: IEEE Access (2024)\n인용: 0회\n키워드: 3D Gaussian Splatting, Multi-View Stereo, SLAM, 사각 복원\n문제: 기존 3D 복원 방법의 기하학적 붕괴 문제 해결\n방법: 온라인 MVS를 활용한 강건한 3D Gaussian Splatting 매핑\n결과: PSNR 11.6% 향상, 실시간성 확보 및 대규모 실외 환경에서도 높은 재구성 품질", "keywords": ["3D Gaussian Splatting", "Multi-View Stereo", "SLAM", "사각 복원"], "importance": 0.44999999999999996, "meta": {"title": "Online 3D Gaussian Splatting Mapping via Online Multi-View Stereo", "year": 2024, "venue": "IEEE Access", "citations": 0}}
{"id": "4df008a0b04d_abstract", "paper_id": "4df008a0b04d", "section": "abstract", "text": "본 논문은 3D 컴퓨터 비전 분야에서 실시간으로 작동 가능한 온라인 Multi-View Stereo를 활용하여 3D Gaussian Splatting 매핑을 구현하는 새로운 방법론을 제안합니다.", "keywords": ["3D Gaussian Splatting", "Multi-View Stereo", "SLAM", "사각 복원"], "importance": 0.36, "meta": {"title": "Online 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "4df008a0b04d_method", "paper_id": "4df008a0b04d", "section": "method", "text": "DROID-SLAM 기반의 연속 프레임 추적 및 Local Window 내 다수 프레임 활용을 통해 고해상도 Depth를 생성하고, 정합성 검증 및 Gaussian 초기화를 수행합니다.", "keywords": ["3D Gaussian Splatting", "Multi-View Stereo", "SLAM", "사각 복원"], "importance": 0.36, "meta": {"title": "Online 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "4df008a0b04d_results", "paper_id": "4df008a0b04d", "section": "results", "text": "제안한 방법이 기존 SOTA 대비 PSNR 11.6% 향상을 보이며, 대규모 실외 환경에서도 강건한 재구성 품질을 확보하였습니다.", "keywords": ["3D Gaussian Splatting", "Multi-View Stereo", "SLAM", "사각 복원"], "importance": 0.36, "meta": {"title": "Online 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "4df008a0b04d_contributions", "paper_id": "4df008a0b04d", "section": "contributions", "text": "논문 \"Online 3D Gaussian Splatting Mapping via Online Multi-View Stereo\"의 핵심 기여:\n- 온라인 MVS와 3DGS를 결합한 새로운 파이프라인 제안\n- Uncertainty-aware NVS를 통한 향상된 3D Scene 완성도\n\n제안 방법: 온라인 MVS를 활용한 강건한 3D Gaussian Splatting 매핑", "keywords": ["3D Gaussian Splatting", "Multi-View Stereo", "SLAM", "사각 복원"], "importance": 0.44999999999999996, "meta": {"title": "Online 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
