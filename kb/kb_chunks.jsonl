{"id": "ebd43503423c_meta", "paper_id": "ebd43503423c", "section": "meta", "text": "논문: Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation\n저자: Junkyu Park, Byeonggwon Lee, Sanggi Lee\n발표: Electronics (2025)\n인용: 0회\n키워드: 3D Gaussian Splatting, SLAM, stereo depth estimation, online mapping, neural rendering\n문제: 오프라인 3DGS 방법의 비효율성과 스테레오 SLAM의 제한된 깊이 정밀성을 해결\n방법: Stereo-GS는 rectified 스테레오 이미지 쌍에서 깊이 맵을 추정하여 3DGS 모델을 온라인으로 재구성합니다.\n결과: EuRoC에서 평균 PSNR 23.70, TartanAir에서 22.47을 달성하였으며, Artefacts를 최소화하며 기존 방법들보다 높은 시각적 품질을 보여줍니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.5, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation", "year": 2025, "venue": "Electronics", "citations": 0}}
{"id": "ebd43503423c_abstract", "paper_id": "ebd43503423c", "section": "abstract", "text": "이 논문에서는 Stereo-GS라는 실시간 온라인 3D Gaussian Splatting 시스템을 제안합니다. 이 시스템은 스트리밍 스테레오 이미지 쌍으로부터 사진처럼 사실적인 3D 장면을 재구성할 수 있습니다. Stereo-GS는 rectified 스테레오 기하학을 사용하여 깊이 맵을 직접 추정함으로써 이전의 오프라인 3DGS 방법들이 가진 한계를 극복합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.4, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_problem", "paper_id": "ebd43503423c", "section": "problem", "text": "기존의 오프라인 3D Gaussian Splatting(3DGS) 방법은 고밀도 다중뷰 입력이나 미리 계산된 깊이 정보를 필요로 하며, 이는 SLAM 시나리오에서는 비효율적입니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.4, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_method", "paper_id": "ebd43503423c", "section": "method", "text": "이 방법은 DROID-SLAM과 FoundationStereo를 사용하여 카메라의 포즈와 깊이를 추정하고, 두 단계 필터링 파이프라인을 사용하여 깊이 정보의 신뢰성을 높입니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.4, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_results", "paper_id": "ebd43503423c", "section": "results", "text": "Stereo-GS는 EuRoC 및 TartanAir 벤치마크에서 각각 평균 PSNR 0.22 dB 및 2.45 dB의 성능 향상을 보여줍니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.4, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "ebd43503423c_contributions", "paper_id": "ebd43503423c", "section": "contributions", "text": "논문 \"Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation\"의 핵심 기여:\n- 스테레오 깊이 추정을 통해 온라인 3DGS 재구성 프레임워크 제안\n- 두 단계 필터링 메커니즘을 통해 깊이 추정의 신뢰성 개선\n\n제안 방법: Stereo-GS는 rectified 스테레오 이미지 쌍에서 깊이 맵을 추정하여 3DGS 모델을 온라인으로 재구성합니다.", "keywords": ["3D Gaussian Splatting", "SLAM", "stereo depth estimation", "online mapping", "neural rendering"], "importance": 0.5, "meta": {"title": "Stereo-GS: Online 3D Gaussian Splatting Mapping Using Stereo Depth Estimation"}}
{"id": "07af93b9bae7_meta", "paper_id": "07af93b9bae7", "section": "meta", "text": "논문: M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo\n저자: Anonymous\n발표: CVPR (2026)\n인용: 0회\n키워드: Monocular Depth, Multi-View Stereo, Depth Foundation Models, 3D Reconstruction, Bidirectional Refinement\n문제: MVS 기법의 일반화 부족 문제 및 단일 카메라 깊이 예측의 스케일 모호성 문제\n방법: 양방향 상호 개선 전략을 적용하여 MVS와 DFMs의 결합을 강화\n결과: 벤치마크에서 높은 정확도와 일반화를 보였으며, 특별히 가려진 영역과 제한된 시야 중첩이 있는 경우에서도 완전한 깊이 맵을 생성", "keywords": ["Monocular Depth", "Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement"], "importance": 0.6, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo", "year": 2026, "venue": "CVPR", "citations": 0}}
{"id": "07af93b9bae7_abstract", "paper_id": "07af93b9bae7", "section": "abstract", "text": "며 MVS 기반의 3D 복원 기법이 발전했지만 새로운 장면에 대한 일반화가 부족하다. 이를 해결하기 위해, 본 연구는 단일 카메라 깊이 예측 모델 (Depth Foundation Models, DFMs)과 다중 시점 스테레오 (Multi-View Stereo, MVS)를 양방향 상호 개선 전략으로 결합하여 기존의 정적 융합 방식을 개선하였다. 이 접근법은 MVS 깊이를 단일 카메라 예측 스케일 모호성을 해결하는 데 사용하고, 단일 카메라 깊이는 MVS 추정치를 향상시킨다. 제안된 방법은 벤치마크 데이터셋에서 뛰어난 성능을 보였다.", "keywords": ["Monocular Depth", "Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_problem", "paper_id": "07af93b9bae7", "section": "problem", "text": "MVS 기법은 보이지 않는 장면에 대한 일반화가 어렵고, 특히 다른 복잡한 기하학적 구조나 가려진 영역에서 정확도가 떨어지는 문제가 있다.", "keywords": ["Monocular Depth", "Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_method", "paper_id": "07af93b9bae7", "section": "method", "text": "단일 카메라 깊이 모델을 사용하는 DFMs를 기존의 MVS 파이프라인과 결합하여 양방향 상호 개선 메커니즘을 제안한다. 이를 통해 단일 카메라 스케일 모호성을 해결하고, 집중 기반 융합을 통해 지역적 기하학적 일관성을 촉진한다.", "keywords": ["Monocular Depth", "Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_results", "paper_id": "07af93b9bae7", "section": "results", "text": "제안된 방법은 벤치마크 데이터셋에서 높은 정확도와 일반화를 보여, 기존 MVS 접근법보다 뛰어난 성능을 발휘했다.", "keywords": ["Monocular Depth", "Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement"], "importance": 0.48, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "07af93b9bae7_contributions", "paper_id": "07af93b9bae7", "section": "contributions", "text": "논문 \"M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo\"의 핵심 기여:\n- 단일 카메라 우선순위를 통합한 새로운 MVS 프레임워크 제안\n- MVS 구조를 강화하기 위한 양방향 상호 개선 메커니즘 제안\n\n제안 방법: 양방향 상호 개선 전략을 적용하여 MVS와 DFMs의 결합을 강화", "keywords": ["Monocular Depth", "Multi-View Stereo", "Depth Foundation Models", "3D Reconstruction", "Bidirectional Refinement"], "importance": 0.6, "meta": {"title": "M2Depth: Unifying Monocular Depth Foundation Priors with Multi-View Stereo"}}
{"id": "9eac4875c0cd_meta", "paper_id": "9eac4875c0cd", "section": "meta", "text": "논문: Online 3D Gaussian Splatting Modeling with Novel View Selection\n저자: Byeonggwon Lee, Junkyu Park, Khang Truong Giang\n발표: 학회/저널명 (2024)\n인용: 0회\n키워드: 3D Gaussian Splatting, Novel View Selection, Real-time 3D Reconstruction\n문제: 기존 3D 재구성의 불완전성과 실시간 처리 문제\n방법: 노벨 뷰 선택(NVS)을 통한 3D Gaussian Splatting 최적화\n결과: PSNR 11.6% 향상, KAIST 드론 데이터 세트에서 우수한 품질의 3D 재구성 달성", "keywords": ["3D Gaussian Splatting", "Novel View Selection", "Real-time 3D Reconstruction"], "importance": 0.30000000000000004, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection", "year": 2024, "venue": "학회/저널명", "citations": 0}}
{"id": "9eac4875c0cd_abstract", "paper_id": "9eac4875c0cd", "section": "abstract", "text": "이 논문은 실시간 3D 장면 재구성을 위한 온라인 3D Gaussian Splatting 모델링을 제안하고, 새로운 뷰 선택 방식을 통해 기존의 제한점을 극복합니다.", "keywords": ["3D Gaussian Splatting", "Novel View Selection", "Real-time 3D Reconstruction"], "importance": 0.24000000000000005, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_problem", "paper_id": "9eac4875c0cd", "section": "problem", "text": "기존 방식의 핵심 프레임에 의존한 재구성으로 인해 완성도가 낮고 실시간 처리가 어렵다는 문제가 있습니다.", "keywords": ["3D Gaussian Splatting", "Novel View Selection", "Real-time 3D Reconstruction"], "importance": 0.24000000000000005, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_method", "paper_id": "9eac4875c0cd", "section": "method", "text": "Gaussian Splatting 모델링에 새로운 뷰 선택 방식을 결합하여 비핵심 프레임을 활용하고 불확실한 영역을 최소화합니다.", "keywords": ["3D Gaussian Splatting", "Novel View Selection", "Real-time 3D Reconstruction"], "importance": 0.24000000000000005, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_results", "paper_id": "9eac4875c0cd", "section": "results", "text": "이 방법은 PSNR을 11.6% 향상시키며, 다양한 상황에서 기존 SOTA보다 뛰어난 성능을 보이며, 실시간 재구성을 실현합니다.", "keywords": ["3D Gaussian Splatting", "Novel View Selection", "Real-time 3D Reconstruction"], "importance": 0.24000000000000005, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "9eac4875c0cd_contributions", "paper_id": "9eac4875c0cd", "section": "contributions", "text": "논문 \"Online 3D Gaussian Splatting Modeling with Novel View Selection\"의 핵심 기여:\n- 노벨 뷰 선택 방식 도입\n- 실시간 3D 재구성 향상\n\n제안 방법: 노벨 뷰 선택(NVS)을 통한 3D Gaussian Splatting 최적화", "keywords": ["3D Gaussian Splatting", "Novel View Selection", "Real-time 3D Reconstruction"], "importance": 0.30000000000000004, "meta": {"title": "Online 3D Gaussian Splatting Modeling with Novel View Selection"}}
{"id": "c61cbd659b1d_meta", "paper_id": "c61cbd659b1d", "section": "meta", "text": "논문: MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo\n저자: Byeonggwon Lee, Junky Park, Khang Truong Giang\n발표: 학회/저널명 (2025)\n인용: 0회\n키워드: 온라인 다중-뷰 스테레오, 3D Gaussian Splatting, 신경 렌더링, Dense SLAM, 3D 모델링, 깊이 추정\n문제: RGB 이미지 기반의 저해상도 및 불확실한 깊이 추정 문제 해결\n방법: 온라인 다중-뷰 스테레오 방식을 활용한 3D Gaussian Splatting 모델링\n결과: 실내 장면에서는 평균 PSNR 약 2 dB 향상, 실외 장면에서는 약 10.28 dB 향상", "keywords": ["온라인 다중-뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "Dense SLAM", "3D 모델링", "깊이 추정"], "importance": 0.35, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo", "year": 2025, "venue": "학회/저널명", "citations": 0}}
{"id": "c61cbd659b1d_abstract", "paper_id": "c61cbd659b1d", "section": "abstract", "text": "본 연구는 RGB 이미지 스트림을 이용한 신경 렌더링을 위한 온라인 3D 모델 생성의 도전을 다룹니다. 기존의 연구들은 Neural Radiance Fields (NeRF)나 3D Gaussian Splatting (3DGS)을 사용하여 이러한 문제를 해결하려 했으나, 대부분의 연구가 주로 대략적인 3D 장면 추정에 집중하고 있었으며, 상세한 재구성을 달성하기에는 미흡했습니다. 이 연구에서는 고품질의 3DGS 모델링을 위한 새로운 프레임워크를 제안하며, 시퀀스 프레임에서의 연속적 기하학적 일관성을 확인하여 깊이 추정의 정밀성을 높이고, 각 키프레임의 효율적인 업데이트를 위한 병렬 백엔드 모듈을 소개합니다.", "keywords": ["온라인 다중-뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "Dense SLAM", "3D 모델링", "깊이 추정"], "importance": 0.27999999999999997, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_method", "paper_id": "c61cbd659b1d", "section": "method", "text": "로컬 시간 창 내의 시퀀스 프레임을 활용한 온라인 다중-뷰 스테레오 방식을 이용하여 3D 정보 정확하게 추정. 심도 정제 및 필터링 과정 포함", "keywords": ["온라인 다중-뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "Dense SLAM", "3D 모델링", "깊이 추정"], "importance": 0.27999999999999997, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_results", "paper_id": "c61cbd659b1d", "section": "results", "text": "우리의 방법은 기존 최첨단 dense SLAM 방법보다 실내 장면에서 약 2 dB의 평균 PSNR 개선을 달성하고, 복잡한 실외 장면에서도 일관된 3D 모델을 신뢰성 있게 생성하며, 대규모 항공 장면을 효과적으로 재구성하여 기존 방법에 비해 약 10.28 dB의 평균 PSNR 향상을 달성했습니다.", "keywords": ["온라인 다중-뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "Dense SLAM", "3D 모델링", "깊이 추정"], "importance": 0.27999999999999997, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
{"id": "c61cbd659b1d_contributions", "paper_id": "c61cbd659b1d", "section": "contributions", "text": "논문 \"MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo\"의 핵심 기여:\n- 온라인 MVS 기술을 활용한 고품질 3DGS 매핑 프레임워크 제안\n- 시퀀스 프레임에서의 포괄적 깊이 필터링을 통합한 온라인 MVS 방법 소개\n- 병렬 프레임워크를 통해 3DGS 모델 최적화 효율성 증가 및 새로운 영역에 대한 초기화 간소화\n- 실내 장면뿐만 아니라 실외 장면에서도 테스트를 통해 일반화 능력을 입증\n\n제안 방법: 온라인 다중-뷰 스테레오 방식을 활용한 3D Gaussian Splatting 모델링", "keywords": ["온라인 다중-뷰 스테레오", "3D Gaussian Splatting", "신경 렌더링", "Dense SLAM", "3D 모델링", "깊이 추정"], "importance": 0.35, "meta": {"title": "MVS-GS: High-Quality 3D Gaussian Splatting Mapping via Online Multi-View Stereo"}}
